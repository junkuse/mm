# ARIMA MODEL

from statsmodels.tsa.arima_model import ARIMA
from matplotlib import pyplot

model = ARIMA(close, order=(2,0,2))
model_fit = model.fit()
residuals = model_fit.resid
residuals.plot()
  
#CALCULATE TREND
def cal_trend(x, y):
  a = sum(y)/len(y)
  x_coded = [(i-(sum(x)/len(x)))*2 for i in x]
  b = sum([i*j for i,j in zip(x_coded,y)]) / sum([pow(i,2) for i in x_coded])
  y_pred = [a+(b*i) for i in x_coded]
  pre_trend = [(i/j)*100 for i,j in zip(y, y_pred)]
  cyc_res = [((i-j)/j)*100 for i,j in zip(y, y_pred)]
  return [y_pred, pre_trend, cyc_res]

Year = [1989, 1990, 1991, 1992, 1993, 1994, 1995]
Boxes = [21, 19.4, 22.6, 28.2, 30.4, 24, 25]
#plt.xlabel('Year')
#plt.plot(Year, Boxes, color = 'blue')
Boxes_pred, pre_trend, cyc_res = cal_trend(Year, Boxes)
#plt.plot(Year, Boxes_pred, color = 'red')
print("Maximum Fluctuation in Percent of Trend: "+ str(Year[pre_trend.index(max([abs(i) for i in pre_trend]))]))
print("Maximum Fluctuation in Cyclic Residual: "+ str(Year[cyc_res.index(max([abs(i) for i in cyc_res]))]))


# DESEASONALIZE

def compute_seasonal_index(x, num_yrs):
  four_quarter_moving_total_avg = []
  four_quarter_centered_moving_avg = []
  percent_actual_to_moving_avg = []
  # four_quarter_moving_total_avg
  j = 0
  for i in range(len(x)-3):
    temp = (x[i] + x[i+1] + x[i+2] + x[i+3]) / 4
    four_quarter_moving_total_avg.append(temp)
  #print("\nFour quarter moving averages: ", four_quarter_moving_avg)

  # four_quarter_centered_moving_avg
  for i in range(len(four_quarter_moving_total_avg)-1):
    temp = (four_quarter_moving_total_avg[i] + four_quarter_moving_total_avg[i+1]) / 2
    four_quarter_centered_moving_avg.append(temp)
  #print("\nFour quarter centered moving averages: ", four_quarter_centered_moving_avg)

  # percent_actual_to_moving_avg
  for i in range(2, len(x)-2):
    temp = (x[i] / four_quarter_centered_moving_avg[j]) * 100
    j += 1
    percent_actual_to_moving_avg.append(temp)
  #print("\nPercentage of actual to moving averages: ", percent_actual_to_moving_avg)

  # Reordering the data 
  diff = [0, 0] + percent_actual_to_moving_avg
  n = len(diff) % 4
  diff += [0 for _ in range(n)]
  #print("\nDiff values: ", diff)
  track = []
  modified_mean = []
  width = len(diff) // num_yrs
  for i in range(4):
    temp = []
    for j in range(0, num_yrs):
      temp.append(diff[width*j+i])
    track.append(temp)
  #print("\nTrack values: ", track)

  for i in range(len(track)):
    track[i] = [i for i in track[i] if i != 0]
    a = min(track[i])
    b = max(track[i])
    track[i].remove(a)
    track[i].remove(b)
    n = len(track[i])
    modified_mean.append(sum(track[i]) / n)
  #print("\nModified means / Trimmed means: ", modified_mean)
  tot = sum(modified_mean)
  adjusting_factor = 400 / tot
  seasonal_indices = []
  for i in range(len(modified_mean)):
    seasonal_indices.append(modified_mean[i] * adjusting_factor)
  #print("\nSeasonal indices: ", seasonal_indices)
  modified_seasonal_indices = [i/100 for i in seasonal_indices]
  modified_seasonal_indices = modified_seasonal_indices * num_yrs
  deseasonalized_data = []
  for i in range(len(x)):
    deseasonalized_data.append((x[i] / modified_seasonal_indices[i]))
  #print("\nDeseasonalized data: ", deseasonalized_data)

  return {'four_quarter_moving_avg':four_quarter_moving_total_avg, 'four_quarter_centered_moving_avg':four_quarter_centered_moving_avg, 'percent_actual_to_moving_avg':percent_actual_to_moving_avg, 'diff':diff, 'track':track, 'modified_mean':modified_mean, 'seasonal_indices':seasonal_indices, 'deseasonalized_data':deseasonalized_data}
  

def identify_trend(x, num_yrs):
  n = len(x)
  coding = [0 for _ in range(n)]
  mid = (n//2) - 1
  coding[mid] = -0.5
  coding[mid+1] = 0.5
  for i in range(mid-1, -1, -1):
    coding[i] = coding[i+1] - 1
  for i in range(mid+2, n):
    coding[i] = coding[i-1] + 1
  for i in range(n):
    coding[i] *= 2
  xy = [i*j for i,j in zip(coding, x)]
  x_2 = [i**2 for i in coding]
  sum_y = sum(x)
  sum_x_2 = sum(x_2)
  sum_xy = sum(xy)
  #print("\nSummation y: ", sum_y)
  #print("\nSummation xy: ", sum_xy)
  #print("\nSummation x2: ", sum_x_2)
  b = sum_xy / sum_x_2
  a = sum_y / (num_yrs * 4)
  return {'a':a, 'b':b, 'coding':coding}

actual_sales = [102, 120, 90, 78, 110, 126, 95, 83, 111, 128, 97, 86, 115, 135, 103, 91, 122, 144, 110, 98]

res = compute_seasonal_index(actual_sales, 5)
# 4 quarter centered moving average
print(f"4 quarter centered moving average : {res['four_quarter_centered_moving_avg']}")
# percentage of actual to moving average
print(f"Percentage of actual to moving averages: {res['percent_actual_to_moving_avg']}")
# modified Seasonal Indices, Seasonal Indices
print(f"Modified seasonal indices : {res['modified_mean']}")
print(f"Seasonal Indices : {res['seasonal_indices']}")
coeff = identify_trend(res['deseasonalized_data'], 5)



# ARIMA MODEL

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
pd.options.mode.chained_assignment = None  # default='warn'

df = pd.read_csv('500827.csv',parse_dates=True,index_col='Month')
df=df[["Open Price"]]
df.index.names = ['date']
df.columns=[["Value"]]

df

"""Equation for AR model :"""

def AR(p,df):
  df_temp = df

  #Generating the lagged p terms
  for i in range(1,p+1):
    df_temp['Shifted_values_%d' % i ] = df_temp['Value'].shift(i)

  train_size = (int)(0.8 * df_temp.shape[0])

  #Breaking data set into test and training
  df_train = pd.DataFrame(df_temp[0:train_size])
  df_test = pd.DataFrame(df_temp[train_size:df.shape[0]])

  df_train_2 = df_train.dropna()
  #X contains the lagged values ,hence we skip the first column
  X_train = df_train_2.iloc[:,1:].values.reshape(-1,p)
  #Y contains the value,it is the first column
  y_train = df_train_2.iloc[:,0].values.reshape(-1,1)

  #Running linear regression to generate the coefficents of lagged terms
  from sklearn.linear_model import LinearRegression
  lr = LinearRegression()
  lr.fit(X_train,y_train)

  theta  = lr.coef_.T
  intercept = lr.intercept_
  df_train_2['Predicted_Values'] = X_train.dot(lr.coef_.T) + lr.intercept_
  # df_train_2[['Value','Predicted_Values']].plot()

  X_test = df_test.iloc[:,1:].values.reshape(-1,p)
  df_test['Predicted_Values'] = X_test.dot(lr.coef_.T) + lr.intercept_
  # df_test[['Value','Predicted_Values']].plot()

  RMSE = np.sqrt(mean_squared_error(df_test['Value'], df_test['Predicted_Values']))

  print("The RMSE is :", RMSE,", Value of p : ",p)
  return [df_train_2,df_test,theta,intercept,RMSE]

def MA(q,res):

  for i in range(1,q+1):
    res['Shifted_values_%d' % i ] = res['Residuals'].shift(i)

  train_size = (int)(0.8 * res.shape[0])

  res_train = pd.DataFrame(res[0:train_size])
  res_test = pd.DataFrame(res[train_size:res.shape[0]])

  res_train_2 = res_train.dropna()
  X_train = res_train_2.iloc[:,1:].values.reshape(-1,q)
  y_train = res_train_2.iloc[:,0].values.reshape(-1,1)

  from sklearn.linear_model import LinearRegression
  lr = LinearRegression()
  lr.fit(X_train,y_train)

  theta  = lr.coef_.T
  intercept = lr.intercept_
  res_train_2['Predicted_Values'] = X_train.dot(lr.coef_.T) + lr.intercept_
  # res_train_2[['Residuals','Predicted_Values']].plot()

  X_test = res_test.iloc[:,1:].values.reshape(-1,q)
  res_test['Predicted_Values'] = X_test.dot(lr.coef_.T) + lr.intercept_
  res_test[['Residuals','Predicted_Values']].plot()

  from sklearn.metrics import mean_squared_error
  RMSE = np.sqrt(mean_squared_error(res_test['Residuals'], res_test['Predicted_Values']))

  print("The RMSE is :", RMSE,", Value of q : ",q)
  return [res_train_2,res_test,theta,intercept,RMSE]

def adf_check(time_series):
    result = adfuller(time_series)
    print('Augmented Dickey-Fuller Test:')
    labels = ['ADF Test Statistic','p-value','Number of Lags Used','Number of Observations Used']

    for value,label in zip(result,labels):
        print(label+' : '+str(value) )
    
    if result[1] <= 0.05:
        print("strong evidence against the null hypothesis, reject the null hypothesis. Data has no unit root and is stationary")
    else:
        print("weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \n")

"""#Step 1 : Making the data stationary

Different techniques can be used to make the data stationary, used log and differencing. The additional diff(12) is remove the seasonality.
"""

df_testing = pd.DataFrame(np.log(df["Value"]).diff().diff(12))
adf_check(df_testing.Value.dropna())

# print(df_testing.to_string())
df_testing.plot()

ACF = plot_acf(df_testing.dropna(),lags=50)
PACF = plot_pacf(df_testing.dropna(),lags=50)

"""#Step 2 : Fitting AR Model

We calculate the error on the test-set for each p, and pick the best one.
"""

best_RMSE=100000000000
best_p = -1

for i in range(1,21):
  [df_train,df_test,theta,intercept,RMSE] = AR(i,pd.DataFrame(df_testing.Value))
  if(RMSE<best_RMSE):
    best_RMSE = RMSE
    best_p = i
  
print(best_p)

[df_train,df_test,theta,intercept,RMSE] = AR(best_p,pd.DataFrame(df_testing.Value))

df_c = pd.concat([df_train,df_test])
df_c[['Value','Predicted_Values']].plot()

"""Generating the residuals for MA"""

x=df_c["Value"].values.tolist()
x=[i[0] for i in x]
y= df_c["Predicted_Values"].values.tolist()
y=[i[0] for i in y]

res = pd.DataFrame()
res['Residuals'] = [a - b for a, b in zip(x, y)]

res

res.plot(kind='kde')

"""#Step 3 : Fitting MA on Residuals"""

best_RMSE=100000000000
best_q = -1

for i in range(1,13):
  [res_train,res_test,theta,intercept,RMSE] = MA(i,pd.DataFrame(res.Residuals))
  if(RMSE<best_RMSE):
    best_RMSE = RMSE
    best_q = i
  
print(best_q)

[res_train,res_test,theta,intercept,RMSE] = MA(best_q,pd.DataFrame(res.Residuals))
print(theta)
print(intercept)

res_c = pd.concat([res_train,res_test])

res_c

a=[i[0] for i in df_c["Predicted_Values"].values.tolist()]
b=[i for i in res_c["Predicted_Values"].values.tolist()]
print(len(a), len(b))
df_c["Predicted_Values"]=[x1 + x2 for (x1, x2) in zip(a, b)]

df_c[['Value','Predicted_Values']].plot()

"""# Step 4 : Getting Back Original data

Reversing the steps performed for differencing, as a check the first column (Value) must be the same after reversing the steps.
"""

df_c.Value += np.log(df).shift(1).Value
df_c.Value += np.log(df).diff().shift(12).Value
df_c.Predicted_Values += np.log(df).shift(1).Value 
df_c.Predicted_Values += np.log(df).diff().shift(12).Value
df_c.Value = np.exp(df_c.Value)
df_c.Predicted_Values = np.exp(df_c.Predicted_Values)

df_c

df_c.iloc[30:,:][['Value','Predicted_Values']].plot()
